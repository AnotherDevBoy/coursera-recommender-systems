{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.data import generate_top_n_for_all_users, get_ratings, get_predictions, get_top_n, get_relevant_items_for_user, set_items, get_users, set_ratings, set_predictions\n",
    "\n",
    "# Metric Imports\n",
    "from lib.availability import availability_for_user\n",
    "from lib.coverage import is_user_covered, category_coverage_for_user\n",
    "from lib.diversity import intralist_price_diversity_for_user, intralist_category_diversity_for_user\n",
    "from lib.mrr import mrr_for_user\n",
    "from lib.precision import average_precision_for_user, f1_score\n",
    "from lib.rmse import rmse_for_user\n",
    "from lib.serendipity import serendipity_for_user\n",
    "from lib.ndcg import ndcg\n",
    "\n",
    "from lib.utils import read_items_from_file, read_ratings_from_file, read_predictions_from_file, calculate_statistics, generate_output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File data/weighted_mf_0_cbf.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4b560d72e3ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mALGORITHMS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m   \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_predictions_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m   \u001b[0mset_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\coursera-recommender-systems\\capstone\\metrics\\lib\\utils.pyc\u001b[0m in \u001b[0;36mread_predictions_from_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_predictions_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[0mpredictions_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File data/weighted_mf_0_cbf.csv does not exist"
     ]
    }
   ],
   "source": [
    "BASELINE_ALGORITHMS = ['cbf', 'mf', 'item-item']\n",
    "WEIGHTS = [0.10, 0.25, 0.50, 0.75, 0.85, 0.90, 0.95]\n",
    "\n",
    "algorithms_to_study = []\n",
    "\n",
    "for weight in WEIGHTS:\n",
    "    for algorithm_1 in BASELINE_ALGORITHMS:\n",
    "        for algorithm_2 in BASELINE_ALGORITHMS:\n",
    "            if algorithm_1 != algorithm_2:\n",
    "                algorithms_to_study.append('weighted_%s_%d_%s' % (algorithm_2, weight, algorithm_1))\n",
    "                \n",
    "ALGORITHMS = ['user-user'] + BASELINE_ALGORITHMS + algorithms_to_study\n",
    "\n",
    "SINGLEVALUE_METRICS = ['Coverage.Item', 'Coverage.User']\n",
    "MULTIVALUE_METRICS = ['Availability', 'MRR', 'Serendipity',\n",
    "                    'MAP', 'RMSE.Predict', 'RMSE.TopN', 'nDCG', 'Diversity.Price', 'Diversity.Category', 'F1']\n",
    "\n",
    "set_ratings(read_ratings_from_file())\n",
    "ITEMS = read_items_from_file()\n",
    "set_items(ITEMS)\n",
    "ALL_CATEGORIES = set(map(lambda x: x['Category'], ITEMS))\n",
    "\n",
    "results = {}\n",
    "\n",
    "for metric in (SINGLEVALUE_METRICS + MULTIVALUE_METRICS):\n",
    "  results[metric] = {}\n",
    "\n",
    "for algorithm in ALGORITHMS:\n",
    "  predictions = read_predictions_from_file(algorithm)\n",
    "  set_predictions(predictions)\n",
    "\n",
    "  users = get_users()\n",
    "  generate_top_n_for_all_users(users)\n",
    "\n",
    "  items_recommended = set()\n",
    "  users_covered = 0.0\n",
    "\n",
    "  availability_values = []\n",
    "  mrr_values = []\n",
    "  serendipity_values = []\n",
    "  map_values = []\n",
    "  f1_values = []\n",
    "  rmse_predict_values = []\n",
    "  rmse_top_values = []\n",
    "  ndcg_values = []\n",
    "  diversity_price_values = []\n",
    "  diversity_category_values = []\n",
    "\n",
    "  for user_id in users:\n",
    "    top_n = get_top_n(user_id, 5)\n",
    "    user_ratings = get_ratings(user_id)\n",
    "    user_relevant_items = get_relevant_items_for_user(user_id)\n",
    "    user_predictions = get_predictions(user_id)\n",
    "\n",
    "    # Coverage Metrics\n",
    "    items_recommended = items_recommended | set(top_n['Item'])\n",
    "\n",
    "    if is_user_covered(top_n):\n",
    "      users_covered += 1.0\n",
    "\n",
    "    # Other metrics\n",
    "    availability_values.append(availability_for_user(top_n))\n",
    "    mrr_values.append(mrr_for_user(top_n, user_relevant_items))\n",
    "    serendipity_values.append(serendipity_for_user(top_n, user_id))\n",
    "    map_values.append(average_precision_for_user(top_n, user_id))\n",
    "    f1_values.append(f1_score(top_n, user_id))\n",
    "    rmse_predict = rmse_for_user(user_id, user_ratings, user_predictions)\n",
    "    rmse_predict_values.append(rmse_predict)\n",
    "    rmse_top_n = rmse_for_user(user_id, user_ratings, top_n)\n",
    "    rmse_top_values.append(rmse_top_n)\n",
    "    ndcg_values.append(ndcg(user_id, top_n))\n",
    "    diversity_price_values.append(intralist_price_diversity_for_user(top_n))\n",
    "    diversity_category_values.append(intralist_category_diversity_for_user(top_n))\n",
    "\n",
    "  results['Availability'][algorithm] = calculate_statistics(availability_values, algorithm)\n",
    "  results['MRR'][algorithm] = calculate_statistics(mrr_values, algorithm)\n",
    "  results['Serendipity'][algorithm] = calculate_statistics(serendipity_values, algorithm)\n",
    "  results['MAP'][algorithm] = calculate_statistics(map_values, algorithm)\n",
    "  results['F1'][algorithm] = calculate_statistics(f1_values, algorithm)\n",
    "  results['RMSE.Predict'][algorithm] = calculate_statistics(rmse_predict_values, algorithm)\n",
    "  results['RMSE.TopN'][algorithm] = calculate_statistics(rmse_top_values, algorithm)\n",
    "  results['nDCG'][algorithm] = calculate_statistics(ndcg_values, algorithm)\n",
    "  results['Diversity.Price'][algorithm] = calculate_statistics(diversity_price_values, algorithm)\n",
    "  results['Diversity.Category'][algorithm] = calculate_statistics(diversity_category_values, algorithm)\n",
    "\n",
    "  results['Coverage.Item'][algorithm] = [float(len(items_recommended))/float(len(ITEMS))]\n",
    "  results['Coverage.User'][algorithm] = [users_covered/float(len(users))]\n",
    "\n",
    "results['Availability'] = pd.concat([results['Availability'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['MRR'] = pd.concat([results['MRR'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['Serendipity'] = pd.concat([results['Serendipity'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['MAP'] = pd.concat([results['MAP'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['F1'] = pd.concat([results['F1'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['RMSE.Predict'] = pd.concat([results['RMSE.Predict'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['RMSE.TopN'] = pd.concat([results['RMSE.TopN'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['nDCG'] = pd.concat([results['nDCG'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['Diversity.Price'] = pd.concat([results['Diversity.Price'][algorithm] for algorithm in ALGORITHMS])\n",
    "results['Diversity.Category'] = pd.concat([results['Diversity.Category'][algorithm] for algorithm in ALGORITHMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 16 # inch\n",
    "aspect = 0.8 # height/width ratio\n",
    "height = width*aspect\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "n_groups = 1\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['Availability']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('Availability')\n",
    "ax.set_title('Availability per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['Serendipity']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('Serendipity')\n",
    "ax.set_title('Serendipity per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['MAP']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('MAP')\n",
    "ax.set_title('MAP per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['F1']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('F1')\n",
    "ax.set_title('F1 per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['RMSE.Predict']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('RMSE.Predict')\n",
    "ax.set_title('RMSE.Predict per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['RMSE.TopN']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('RMSE.TopN')\n",
    "ax.set_title('RMSE.TopN per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['nDCG']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('nDCG')\n",
    "ax.set_title('nDCG per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['Diversity.Price']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('Diversity.Price')\n",
    "ax.set_title('Diversity.Price per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = results['Diversity.Category']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(0, len(ALGORITHMS)):\n",
    "    algorithm = ALGORITHMS[i]\n",
    "    bar = ax.bar(index + i*bar_width, metric.loc[algorithm]['mean'], \n",
    "                 width=bar_width, yerr=metric.loc[algorithm]['std'], label=algorithm, tick_label='')\n",
    "    \n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('Diversity.Category')\n",
    "ax.set_title('Diversity.Category per Algorithm')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results['Coverage.Item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results['Coverage.User'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
